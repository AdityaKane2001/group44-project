{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmu = pd.read_csv('booksummaries.txt', sep='\\t', header=None)\n",
    "df_cmu = df_cmu.rename(columns={0:\"id_wikipedia\", 1:'id_freebase', 2:'title', 3:'author', 4:'pub_date', 5:'genre', 6:'summary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting genre into comma-separated string\n",
    "def extract_genre(d):\n",
    "    output = ''\n",
    "    if pd.isna(d):\n",
    "        return\n",
    "    for genre in eval(d).values():\n",
    "        output = output + genre + ', '\n",
    "    output = output[:-2]\n",
    "    return output\n",
    "\n",
    "extract_genre(df_cmu['genre'][0])\n",
    "\n",
    "df_cmu['genre'] = df_cmu['genre'].apply(extract_genre)\n",
    "\n",
    "# Drop books missing genre list\n",
    "df_cmu = df_cmu[df_cmu['genre'].notna()]\n",
    "df_cmu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize summary text\n",
    "word_tokenize(df_cmu['summary'][0])\n",
    "\n",
    "df_cmu['summary_token'] = df_cmu['summary'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords included in the NLTK stopwords dictionary\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "\n",
    "df_cmu['summary_token'] = df_cmu['summary_token'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing tokens: ~1.5 min. runtime for Andrew\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(token, 'n') for token in tokens]\n",
    "    lemmas = [lemmatizer.lemmatize(lemma, 'v') for lemma in lemmas]\n",
    "    lemmas = [lemmatizer.lemmatize(lemma, 'a') for lemma in lemmas]\n",
    "    lemmas = [lemmatizer.lemmatize(lemma, 'r') for lemma in lemmas]\n",
    "    lemmas = [lemmatizer.lemmatize(lemma, 's') for lemma in lemmas]\n",
    "    return lemmas\n",
    "\n",
    "df_cmu['summary_token'] = df_cmu['summary_token'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61315d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv\n",
    "df_cmu.to_csv('cmu_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2580b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82851bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cmu_cleaned.csv', converters={'filtered_genre':literal_eval, 'summary_token': lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae04bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tok = list(df['summary_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd65b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_dict = corpora.Dictionary(summary_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dad141",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = [corp_dict.doc2bow(tok) for tok in summary_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f57ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_matrix = np.zeros((10,83))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,86):\n",
    "    for seed in range(10):\n",
    "        LDA = gensim.models.ldamodel.LdaModel(bow, i, corp_dict, random_state=seed, per_word_topics=True)\n",
    "        coherence = CoherenceModel(model=LDA, texts=summary_tok, dictionary=corp_dict, coherence='c_v')\n",
    "        c = coherence.get_coherence()\n",
    "        coherence_matrix[seed, i-3] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_agg = np.mean(coherence_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ba81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,86):\n",
    "    avg = coherence_agg[i-3]\n",
    "    print('Mean Coherence for', i, 'Topics:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(46,101):\n",
    "    LDA = gensim.models.ldamodel.LdaModel(bow, i, corp_dict, random_state=seed, per_word_topics=True)\n",
    "    coherence = CoherenceModel(model=LDA, texts=summary_tok, dictionary=corp_dict, coherence='c_v')\n",
    "    print('Coherence for', i, 'Topics:', coherence.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a946947",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel(bow, 56, corp_dict, random_state=27, per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4043aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10da145",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(LDA, bow, corp_dict)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
